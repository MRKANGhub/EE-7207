# 神经网络

# 1.网络类型 

## 1.1 神经元网络

**人工神经网络**（英语：Artificial Neural Network，ANN），简称**神经网络**（Neural Network，NN）或**类神经网络**，在[机器学习](https://zh.wikipedia.org/wiki/机器学习)和[认知科学](https://zh.wikipedia.org/wiki/认知科学)领域，是一种[模仿](https://zh.wikipedia.org/wiki/仿生學)[生物神经网络](https://zh.wikipedia.org/wiki/生物神经网络)（动物的[中枢神经系统](https://zh.wikipedia.org/wiki/中樞神經系統)，特别是[大脑](https://zh.wikipedia.org/wiki/大脑)）的结构和功能的[数学模型](https://zh.wikipedia.org/wiki/数学模型)或[计算模型](https://zh.wikipedia.org/wiki/计算模型)，用于对[函数](https://zh.wikipedia.org/wiki/函数)进行估计或近似。神经网络由大量的人工神经元联结进行计算。大多数情况下人工神经网络能在外界信息的基础上改变内部结构，是一种[自适应系统](https://zh.wikipedia.org/w/index.php?title=自适应系统&action=edit&redlink=1)，通俗地讲就是具备学习功能。现代神经网络是一种[非线性](https://zh.wikipedia.org/wiki/非线性)[统计性数据建模](https://zh.wikipedia.org/w/index.php?title=统计性数据建模&action=edit&redlink=1)工具，神经网络通常是通过一个基于数学统计学类型的学习方法（Learning Method）得以优化，所以也是数学[统计学](https://zh.wikipedia.org/wiki/统计学)方法的一种实际应用，通过统计学的标准数学方法我们能够得到大量的可以用函数来表达的局部结构空间，另一方面在人工智能学的人工感知领域，我们通过数学统计学的应用可以来做人工感知方面的决定问题（也就是说通过统计学的方法，人工神经网络能够类似人一样具有简单的决定能力和简单的判断能力），这种方法比起正式的逻辑学推理演算更具有优势。

## 1.2 网络结构 

### 1.2.1前馈网络（feed-forward Network）

神经网络可以当做是能够拟合任意函数的黑盒子，只要训练数据足够，给定特定的x，就能得到希望的y。

神经网络可以当做是能够拟合任意函数的黑盒子，只要训练数据足够，给定特定的x，就能得到希望的y前向网络(前馈网络)：网络可以分为若干“层”，各层按信号传输先后顺序依次排列，第i层的神经元只接受第(i-1)层神经元给出的信号，各神经元之间没有反馈。前馈型网络可用一有向无环路图表示。

[![z8aN2n.png](https://s1.ax1x.com/2022/11/23/z8aN2n.png)](https://imgse.com/i/z8aN2n)

### 1.2.2 反馈网络（feedback/recurrent Neural Network）

每个节点都表示一个计算单元，同时接受外加输入和其它各节点的反馈输入，每个节点也都直接向外部输出。Hopfield网络即属此种类型。在某些反馈网络中，各神经元除接受外加输入与其它各节点反馈输入之外，还包括自身反馈。有时，反馈型神经网络也可表示为一张完全的无向图。

[![xrXy80.jpg](https://s1.ax1x.com/2022/10/18/xrXy80.jpg)](https://imgse.com/i/xrXy80)

## 1.3 回归问题和分类问题

回归旨在近似一个映射函数，从输入变量(x)到连续输出变量(y)，分类的目的是将输入x映射到离散的输出y。它也可以解释为找到一个决策边界来分离不同类中的样本。

# 2.网络规则

## 2.1 error-correction learning

纠错学习的神经网络的学习是的的过程确定网络中所有连接的权重。n误差修正学习时，权重的调整是基于误差的，误差定义为网络输出与目标值之间的差值:
$$
\leftarrow \Delta \mathrm{w}_{\mathrm{kj}}(\mathrm{n})=\eta \mathrm{e}_{\mathrm{k}}(\mathrm{n}) \mathrm{x}_{\mathrm{j}}(\mathrm{n})
$$
a是一个正常数，它决定了误差信号的权值调整和相应的权值调整
$$
\mathrm{w}_{\mathrm{kj}}(\mathrm{n}+1)=\mathrm{w}_{\mathrm{kj}}(\mathrm{n})+\Delta \mathrm{w}_{\mathrm{kj}}(\mathrm{n})
$$

## 2.2 Hebbian Learning

Hebbian学习规则可以表述为:

(i)如果两个神经元在要么一边的突触,即。连接，同时被激活，然后那个突触的强度被选择性地增强。

(ii)如果突触两侧的两个神经元被异步激活，则突触是有选择性地削弱或消除

通常，Hebbian学习规则用当前神经元的输入与输出的乘积更新自己的权重。

![\Delta w_{ij}=\eta o_jx_i](https://private.codecogs.com/gif.latex?%5CDelta%20w_%7Bij%7D%3D%5Ceta%20o_jx_i)

其中：![o_j](https://private.codecogs.com/gif.latex?o_j)是第![j](https://private.codecogs.com/gif.latex?j)个神经元的输出，![x_i](https://private.codecogs.com/gif.latex?x_i)是神经元的第![i](https://private.codecogs.com/gif.latex?i)个输入。![w_{ij}](https://private.codecogs.com/gif.latex?w_%7Bij%7D)是神经元![j](https://private.codecogs.com/gif.latex?j)与第![i](https://private.codecogs.com/gif.latex?i)个输入数据![x_i](https://private.codecogs.com/gif.latex?x_i)之间的权重。

## 2.3 competitive Learning 

顾名思义，在竞争学习中，输出神经元神经网络之间存在竞争。而在一个神经网络基于在Hebbian学习几个输出在这种情况下，神经元可能同时活跃的竞争学习只有一个神经元是活跃的。

（1）一组完全相同的神经元，除了一些随机分布的突触权重，因此对a的反应不同给定的集合输入模式;

（2）允许神经元竞争争取回应的权利到一个给定输入的子集只有这样一个神经元在同一时间是活动的。的神经元赢得比赛的被称为a赢家都神经元。

（3）一种允许获胜神经元更新权重的机制

[![zVTSgA.png](https://s1.ax1x.com/2022/11/16/zVTSgA.png)](https://imgse.com/i/zVTSgA)

# 3. Hopfield Network

## 3.1 原理

Hopfield网络是反馈网络的一种，类似人类大脑的记忆原理，即通过关联的方式，将某一件事物与周围场最中的其他事物建立关联，当人们忘记了一部分信息后，可以通过场最信息回忆起来，将缺失的信息找回。通过在反馈神经网络中引入能量函数的概念，使其运行稳定性的判断有了可靠依据，由权重值派生出能量函数是从能量高的位置向能量低的位置转化，稳定点的势能比较低。基于动力学系统理论处理状态的变换，系统的稳定态可用于描述记忆。

特点 

（1）单层

（2）每一个神经元输出都反馈给其他神经元除了他自身

（3）使用bi-polar激活函数

## 3.2 规则和问题

在Hopfield网络中，学习算法是基于Hebb学习规则，权值调整规则为若相邻两个神经元同时处于兴奋状态，那么他们之间的连接应增强，权值增大；反之，则权值减少。Hopfield网络存在的问题：假记忆问题、存储容量限制、存在局部最优问题。



## 3.3 网络结构

Hopfield[神经网络](https://so.csdn.net/so/search?q=神经网络&spm=1001.2101.3001.7020)是一种比较特殊的网络，它不像一般的神经网络那样有输入层和输出层，并且通过训练来改变神经网络中的参数，最终实现预测、识别等功能。Hopfield网络只有一群神经元节点，所有节点之间相互连接。



[![xrgfMV.png](https://s1.ax1x.com/2022/10/18/xrgfMV.png)](https://imgse.com/i/xrgfMV)

## 3.4 学习过程

[![xrg22q.jpg](https://s1.ax1x.com/2022/10/18/xrg22q.jpg)](https://imgse.com/i/xrg22q)

## 3.5 能量函数

能量函数用来表征系统的稳定性，在满足一定的条件下，某种“能量函数”的能量在网络运行过程中不断减小，当能量最终定于一个常数时，网络趋于最终的稳定态。
$$
E(\mathbf{0})=-\frac{1}{2} \mathbf{o}^T \mathbf{W o}
$$
利用网络的能量数可实现优化求解功能。网络的能量函数在网络状态按一定规则变化时，能自动趋向能量的极小点。如果把一个待求解问题的目标函数以网络能量函数的形式表达出来，当能量函数趋于最小时，对应的网络状态就是问题的最优解。网络的初态可视为问题的初始解，而网络从初态向稳态的收敛过程便是优化计算的过程，这种寻优搜索是在网络演变过程中自动完成的。

## 3.6 权重确定

非线性激活函数的存在并不一定需要非线性解的形成。在Hebbian学习中，利用突触前和突触后信号之间的相关性来确定权重。接下来，我们将根据上面的思路开发一个形成权重矩阵W的程序。

## 3.7 记忆功能

记忆阶段：学习过程

检索阶段，一个称为探针的d维向量x被强加在Hopfield网络上作为它的输入向量的元素有+1或-1。探头通常是基本函数的不完整或有噪声的版本内存信息检索然后收益在符合动态规则，其中网络的状态在每次迭代时都更新。继续更新状态，直到没有进一步的变化发生。

**有时候记忆功能不能实现**

（1）输出不经常稳定

（2）spurious状态会出现

通过降低纬度和提高数量可以提高网络的记忆能力。



# 4.双向联想记忆神经网络 - BAM网络

## 4.1 网络结构

BAM网络是一种双层双向网络（属于反馈网络），当向其中一层加入输入信号时，另一层可得到输出。由于初始模式可以作用于网络的任一层，信息可以双向传播，所以没有明确的输入层或输出层。可将其中的一层称为X层，有n个神经元节点；另一层称为Y层，有m个神经元节点。两层的状态向量可取单极性二进制０或１，也可以取双极性离散值１或－１。如果令由X到Y的权矩阵为W，则由Y到X的权矩阵便是其转置矩阵WT

下列图片是BAM网络简图：

[![xrgy5j.png](https://s1.ax1x.com/2022/10/18/xrgy5j.png)](https://imgse.com/i/xrgy5j)

## 4.2 学习过程

$$
\begin{aligned}
&\boldsymbol{w}_{i j}=\sum_{k=1}^N \boldsymbol{x}_{k i} \boldsymbol{y}_{k j} \\
&\mathbf{W}=\sum_{i=1}^N \mathbf{x}_i \mathbf{y}_i^T
\end{aligned}
$$



# 5.自组织映射 - SOM网络

## 5.1网络结构

自组织映射(Self-organizing map, SOM)通过学习输入空间中的数据，生成一个低维、离散的映射(Map)，从某种程度上也可看成一种降维算法。因此，SOM的主要目标是将任意维度的输入信号模式**转换**为一维或二维离散映射，并以拓扑有序的方式自适应地执行这种变换。（类似人类大脑映射）。

SOM是一种**无监督**的人工神经网络。不同于一般神经网络基于损失函数的反向传递来训练，它运用**竞争学习**(competitive learning)策略,依靠神经元之间互相竞争逐步优化网络。且使用近邻关系函数(neighborhood function)来维持输入空间的拓扑结构。

下列图片是som网络简图：

[![      ](https://s1.ax1x.com/2022/10/18/xrg4qU.jpg)](https://imgse.com/i/xrg4qU)

## 5.2学习过程

##### 竞争过程(Competitive Process)

竞争学习规则的生理学基础是神经细胞的侧抑制现象: 当一个神经细胞兴奋后，会对其周围的神经细胞产生抑制作用。最强的抑制作用是竞争获胜的“唯我独兴”,这种做法称为胜者独占WTA(Winner Take All)。竞争学习规则就是从神经细胞的侧抑制现象获得的.

在 SOM 中,竞争层的各个神经元会参照输入的 N 维的数据（x）和连接权重（权重 w）,w 的范围在{0,1}之间，以正规化(Normalized)的任意值来初始化。在学习过程中，会计算输入 x 与所有神经元的权重 w 之间的距离。当距离最小时该神经元成为胜者，这就是竞争的过程。

##### 合作过程(Cooperation Process)

这一过程是允许竞争过程的胜者与其邻近的神经元,对提供的输入数据进行学习.为了对相似的特征在竞争阶层中更敏感地形成地图，“胜者”神经元（winning neuron）依据固定的函数来决定邻近的神经元,同时此神经元的相应权重也会得到更新. Kohonen 网络的哲学就是 “胜者独占（Winner Take All）”，即只有胜者才有输出，只有胜者才能够更新权重 w。

##### 自适应过程(Adaptation Process)

该过程适应激活函数，使得获胜者神经元和邻近神经元对特定输入值更敏感，同时也更新相应的权重。通过此过程，与胜者神经元邻近的神经元将会比远离的神经元更加适应。适应的大小用过学习率来控制，学习率随着学习的时间而衰减，其对 SOM 的收敛速度起到减小的作用。
$$
\Delta \mathbf{w}_j(n)=\eta(n) h_{j i(x)}(n)\left[\mathbf{x}-\mathbf{w}_j(n)\right]
$$
学习率是会变化的
$$
\eta(\mathbf{n})=\eta_0 \exp \left(-\frac{\mathbf{n}}{\tau_2}\right)
$$
下图是som的学习过程以及计算公式

[![xrgoa4.jpg](https://s1.ax1x.com/2022/10/18/xrgoa4.jpg)](https://imgse.com/i/xrgoa4)

## 5.4 特征映射的性质 (Feature map)

一旦som算法收敛，由算法计算的特征映射会显示输入空间的性质。

(1) 输入空间的近似 (input space approximation)

输出会

(2) 拓扑排序 (topological ordering)

输入空间的位置坐标会影响权重

(3) 密度匹配（density matching）

## 5.5 som的应用

1. 可视化

   som可以将高维数据转化为1，2维数据，起到可视化作用

2. 降维

   som可以将高维数据转化为1，2维数据，起到降纬作用

3. 聚类

   可作为聚类方法，例如选取rbf的中心

# 6.径向基神经网络(Radial Basis Function)

## 6.1 径向基函数

**径向基函数是一个取值仅仅依赖于离原点距离的实值函数，也就是Φ（x）=Φ(‖x‖),或者还可以是到任意一点c的距离，c点称为中心点，也就是Φ（x，c）=Φ(‖x-c‖)。**任意一个满足Φ（x）=Φ(‖x‖)特性的函数Φ都叫做径向基函数，标准的一般使用欧氏距离（也叫做欧式径向基函数），尽管其他距离函数也是可以的。最常用的径向基函数是高斯核函数 ,形式为 k(||x-xc||)=exp{- ||x-xc||^2/(2*σ)^2) } 其中x_c为核函数中心,σ为函数的宽度参数 , 控制了函数的径向作用范围。例如高斯函数：

[![xrgRx0.png](https://s1.ax1x.com/2022/10/18/xrgRx0.png)](https://imgse.com/i/xrgRx0)

## 6.2 网络结构

RBF网络的神经元是一个以gaussian函数为核函数的神经元。

RBF神将网络是一种三层神经网络，其包括输入层、隐层、输出层。从输入空间到隐层空间的变换是非线性的，而从隐层空间到输出层空间变换是线性的。流图如下：

[![xrghrT.png](https://s1.ax1x.com/2022/10/18/xrghrT.png)](https://imgse.com/i/xrghrT)
$$
f[\mathbf{x}(k)]=\sum_{j=1}^m w_j \exp \left(-\frac{\left\|\mathbf{x}(k)-\mathbf{c}_j\right\|^2}{2 \sigma^2}\right)=\sum_{j=1}^m w_j o_j(k)
$$

如何决定神经元中心

（1）随机选择

　首先，选取h个中心做k-means聚类，对于高斯核函数的径向基，方差由公式求解：

![img](https://images2018.cnblogs.com/blog/729758/201807/729758-20180722115608332-1409419168.png)

　　cmax为所选取中心点之间的最大距离。



## 6.3 权重选择

注意到RBF神经网络的输出与隐层神经元的输出呈线性关系，因此第二步的权值估计可以用一个线性最小二乘估计算法。

## 6.4 中心选择

（1）随机选择

​		随机从training samples中选择

（2）训练样本的原型作为神经元中心

​       随机选择中心不能保证良好的输入空间的覆盖率。那么解决这个问题的一个自然的方法就是选择和使用训练样本的原型作为神经元中心。在这种方法中，基起作用是允许将RBF函数的中心只放在输入空间中显示重要数据的区域。SOM神经网络或者k-means可以用来实现这一点的任务。

# 7. SVM支持向量机

## 7.1介绍

前文介绍了径向基函数(RBF)神经网络。我们将学习另一种类型的前馈神经网络,已知的作为支持向量机(SVM)。比如RBF神经网络，支持向量机可以是用于模式分类和回归。核支持向量机一个非常相似的架构RBF神经网络，但他们的学习原理是非常不同的。核支持向量机是一个线性支持向量机的扩展。首先介绍了线性支持向量机的基本原理，然后将其推广为核支持向量机。

## 7.2 线性可分hyperplane

[![zZhwj0.jpg](https://s1.ax1x.com/2022/11/16/zZhwj0.jpg)](https://imgse.com/i/zZhwj0)

### 7.2.1 间隔（margin）

对于给定的权重向量w和偏差b，超平面与最近数据点之间的距离称为分离余量。

[![zZH1Re.jpg](https://s1.ax1x.com/2022/11/16/zZH1Re.jpg)](https://imgse.com/i/zZH1Re)

### 7.2.2 最优超平面（optimal hyperplane）

支持向量机(SVM)的目标是找到分离余地最大的特定超平面。在此条件下，将决策曲面称为最优超平面。

### 7.2.2 支持向量（support vector）

满足上述等式的特定数据点称为支持向量。下图显示了支持向量的位置。支持向量在这类学习机器的操作中起着突出的作用。在概念上，支持向量是那些最接近决策曲面的数据点，因此最难分类。

[![zZHgZq.png](https://s1.ax1x.com/2022/11/16/zZHgZq.png)](https://imgse.com/i/zZHgZq)



## 7.3 线性未分hyperplane

[![zZTml9.jpg](https://s1.ax1x.com/2022/11/16/zZTml9.jpg)](https://imgse.com/i/zZTml9)

## 7.4 非线性—核支持向量机

### 7.4.1 非线性转化线性

在上面，提出了线性支持向量机。如果数据是线性不可分割的，如何构造一个分类器来对数据进行分类，解决方法如下:

步骤1:输入向量的非线性映射高维度特征空间;

步骤2:构建用于分离高维特征空间中数据的最优超平面。

第一步操作是根据cover定理模式的可分离性。考虑一个产生输入空间非线性可分模式的集合。

Cover定理说明了这样一个在满足以下两个条件下，多维空间可以转化为模式线性可分的高概率新特征空间

(a)变换是非线性的情况下。

(b)特征空间的维数足够高。第二步操作利用了建筑的思想一个最优的分离超平面在根据的前面讨论了线性支持向量机，但与一个基本区别:超平面现在被定义为特征空间中的向量的线性函数，而不是原始的输入空间。

[![zZLgeA.jpg](https://s1.ax1x.com/2022/11/16/zZLgeA.jpg)](https://imgse.com/i/zZLgeA)

### 7.4.2 Mercer 定理

**Mercer 定理**：任何半正定的函数都可以作为[核函数](https://baike.baidu.com/item/核函数?fromModule=lemma_inlink)。所谓半正定的函数f(xi,xj)，是指拥有训练数据集合（x1,x2,...xn)，我们定义一个矩阵的元素aij = f(xi,xj)，这个矩阵式n*n的，如果这个矩阵是半正定的，那么f(xi,xj)就称为半正定的函数。Mercer定理是核函数的[充分条件](https://baike.baidu.com/item/充分条件/7958489?fromModule=lemma_inlink)，只要函数满足Mercer定理的条件，那么这个函数就是核函数。

**半正定（positive semi-defined）**：正定和半正定这两个词的英文分别是positive definite和positive semi-definite，其中，definite是一个形容词，表示“明确的、确定的”等意思。

给定一个大小为 n×n 的实对称矩阵 A ，若对于任意长度为 n 的非零向量 x ，有 xTAx>0 恒成立，则矩阵 A 是一个正定矩阵。

给定一个大小为 n×n 的实对称矩阵 A ，若对于任意长度为 n 的向量 x ，有 xTAx≥0 恒成立，则矩阵 A 是一个半正定矩阵。（包含正定矩阵）



### 7.4.3 SVM核函数

的对核K(x, z)的要求是满足mercer定理。在这一要求中，选择它的方式有一定的自由度。经常使用两种内积型核函数:

(i) Polynomial kernel
$$
K(\mathbf{x}, \mathbf{z})=\left(1+\mathbf{x}^T \mathbf{z}\right)^p
$$
where p is a positive integer, and is specified by the user.
(ii) Gaussian kernel
$$
K(\mathbf{x}, \mathbf{z})=\exp \left(-\frac{\|\mathbf{x}-\mathbf{z}\|^2}{2 \sigma^2}\right)
$$
where sigma is the width of the Gaussian kernel, and is specified by the user.



### 7.4.4 核支持向量机设计

(i)多项式和高斯函数的内积核总是满足Mercer定理。

(ii) 支持向量机的基本理论避免了传统径向基函数神经网络设计中经常使用的启发式方法。

(iii)高斯核支持向量机中，神经元的个数及其中心向量(即支持向量)是确定自动

> 凸优化的标准问题有四类：
> \1. Linear Programming(LP)
> \2. Quadratic Programming(QP)
> \3. Semi-Definite Programming(SDP)
> \4. Cone Programming(CP)
>
> 而svm是典型的QP问题。

![zZb79S.png](https://s1.ax1x.com/2022/11/16/zZb79S.png)

[](https://imgse.com/i/zZb79S)



# 8. MLP多层感知机（multilayer perceptron neural network）

## 8.1介绍

多层感知机有三个明显特征

（1）平滑的激活函数，例如sigmoid function

（2）包含一层或多层隐藏层

（3）高度连接性（fully connected）

 MLP神经网络结构的确定

（1） 输入层应该与输入向量的维数相同，即p。

（2）输出层中的神经元数量应该与目标向量的维数相同，即q。

（3）隐含层数通常设置为1

（4）隐藏层中的神经元数量这是一个超参数，通常由试验和确定错误。更多的神经元对于更复杂的问题。

## 8.2 1-d的梯度下降法

[![ze6141.jpg](https://s1.ax1x.com/2022/11/17/ze6141.jpg)](https://imgse.com/i/ze6141)



## 8.3 mlp神经网络学习

### 8.3.1 确定mlp结构

输入层中的神经元数量应该与输入向量的维数相同，即p。

输出层中的神经元数量应该与目标向量的维数相同，即q。

隐藏层的数量通常设置为1

隐藏层中的神经元数量这是一个超参数，通常是通过试错来确定的。总的规则是:更多的神经元处理更复杂的问题。

### 8.3.2 确定权重

### BP算法

[![zeWc7D.jpg](https://s1.ax1x.com/2022/11/17/zeWc7D.jpg)](https://imgse.com/i/zeWc7D)

[![ze4CY4.png](https://s1.ax1x.com/2022/11/17/ze4CY4.png)](https://imgse.com/i/ze4CY4)

### 激活函数（activation function）

计算局部梯度，从而更新每个神经元的权重求解MLP神经网络需要对激活函数求导。要使这个导数存在，激活函数必须是连续的我而且可微的。在MLP神经网络中常用的连续可微非线性激活函数有sigmoid函数和双曲正切函数。

[![ze45cR.jpg](https://s1.ax1x.com/2022/11/17/ze45cR.jpg)](https://imgse.com/i/ze45cR)



[![ze4Fp9.png](https://s1.ax1x.com/2022/11/17/ze4Fp9.png)](https://imgse.com/i/ze4Fp9)

### 学习率（learning rate parameter）

学习率参数n越小，一次迭代到下一次迭代的突触权重变化就越小。如果我们把学习率参数设得太大，突触权值的大变化可能会使网络学习变得不稳定。一个简单的的方法提高学习速度，同时避免不稳定的危险，就是修改增量规则，加入动量项:

[![ze4j9H.png](https://s1.ax1x.com/2022/11/17/ze4j9H.png)](https://imgse.com/i/ze4j9H)



### 训练模式（training mode）

在一个反向传播算法的实际应用，从一组指定的训练样本到MLP的许多演示中学习结果。在学习过程中，整个训练集的一个完整演示被称为一个epoch。学习过程是在一个直到网络的突触权值稳定下来。对于一组给定的训练样本，反向传播学习可以通过以下三种基本方式之一进行。

**（1）顺序模式**（sequantial mode）

反向传播学习的顺序模式作为在线学习。在这种操作模式中，权重更新在每个训练样本呈现后执行，每次一个样本。

**（2）批处理**（batch mode）

批处理模型中，当历元中的所有样本都呈现给网络时进行权值更新。细节不这里描述，因为顺序模式是的MLP神经网络训练中常用的方法。

**（2）小批处理**（mini-batch mode）

小批量将训练样本分成小批量，用于计算模型误差和更新模型系数。



### 两次计算

在将反向传播算法应用于MLP神经网络训练中，存在两种传播:前向传播和后向传播。

(1)前传在正向传递中，突触权值在整个网络中保持不变网络一个神经元一个神经元，一层一层的计算。

(2)向后传球向后传递从输出层开始，传递错误信号向左通过网络，一层一层，递归地计算每个神经元的局部梯度，并相应地更新权重。

### 反向传播(BP)算法(顺序模式)

(1)初始化。从随机(均匀或正态)分布中选取突触权重。

(2)培训样本的呈现用一个训练样本周期来表示网络。对于每个示例，执行序列前进和后退计算。

(2.1)正向计算在前向计算中，权重是固定的。通过网络一层一层地计算每个神经元的激活信号和输出。

(2.2)逆向计算计算神经元的局部梯度，调整网络的突触权值。重复(2.1)- (2.2)直到所有当前时代的样本只呈现一次。

(3)迭代通过呈现重复步骤(2)新训练样本的时代直到满足以下停止条件。

(i)迭代次数，或

(ii)平均误差的变化足够小。

注意，训练样本的呈现顺序应该是随机的。



## 8.4 隐藏层数目和梯度消失问题

### 隐藏层数目

学习到的神经网络受权值初值的影响，隐层神经元的使用越多，决策面就越复杂。使用多个隐含层时MLP会出现梯度消失问题。

### 梯度消失（gradient vanishing）

这意味着神经元在早期的层学习很多更多的慢慢地比神经元在后面的图层中，这种现象被称为的消失梯度问题。

### 如何解决梯度消失

使用relu（unit，leaky，exponential）作为激活函数。

# 9. 卷积神经网络和图像分类

## 9.1 卷积神经网络介绍

三种layer

**（1）卷积层**

卷积层是CNN的核心构建块。这一层由一组可学习的过滤器组成。每个过滤器在空间上(沿宽度和高度)都很小，但通过输入体积的全部深度扩展。例如，CNN的第一个卷积层中的典型过滤器的大小可能是5x5x3(即宽和高5像素，3像素，因为图像的深度为3，即颜色通道)。在正向传递过程中，我们沿着输入体积的宽度和高度滑动(更准确地说，是卷积)每个滤波器，并在任意位置计算滤波器入口和输入之间的点积。当我们在输入体的宽度和高度上滑动过滤器时，我们将产生一个二维输出(激活映射)，它给出了过滤器在每个空间位置上的响应。每个卷积层都有一组过滤器，每个过滤器都会产生一个单独的二维激活映射。所有这些沿着深度维度的激活映射被堆叠起来以产生输出音量。

**（2）池化层**

当图像太大时，池化层将减少参数的数量。空间池，也称为子采样或下采样，旨在降低每个地图的维数，但保留重要信息。空间池可以有不同的方式:

​	(i)最大池化

​	(ii)平均池化

​	(iii)加和池化

最大池取特征映射的遮蔽区域中最大的元素。平均池和和池平均池和和池取特征映射中被屏蔽区域中所有元素的平均值或总和。

**（3）全连接层**

最后，在经过几个卷积层和最大池化层后，将特征映射平面化，生成全连通层图像特征的向量表示。全连接层执行模式分类如下所示:

## 几种常用到的神经网络

（1）LeNet

[![zn1WNQ.jpg](https://s1.ax1x.com/2022/11/18/zn1WNQ.jpg)](https://imgse.com/i/zn1WNQ)

（2）AleNet

[![zMaaJx.jpg](https://s1.ax1x.com/2022/11/20/zMaaJx.jpg)](https://imgse.com/i/zMaaJx)

（3）VGGNet

[![zlPdHA.png](https://s1.ax1x.com/2022/11/21/zlPdHA.png)](https://imgse.com/i/zlPdHA)



## 9.4 cnn网络训练

CNN的训练基于梯度下降优化，类似于MLP神经网络。但采用了小批处理模式。在这种模式下，梯度是小批量的平均值，称为小批量随机梯度下降(SGD)。不同的cnn采用不同的权值更新规则。以AlexNet为例。将批次大小为128个样品，动量为0.9，权值衰减为0.0005引入权值更新规则:

## 9.5 cnn的transfer学习

### 9.5.1 什么是迁移学习

人类具有跨任务传递知识的内在能力。我们在学习一项任务时获得的知识，我们会以同样的方式利用它来解决相关的任务。任务越相关，我们就越容易转移或交叉利用我们的知识。一些简单的例子是:

(1)学会骑摩托车→学会开车

(2)学习古典钢琴学习爵士钢琴

(3)学习数学和统计学>学习机器学习

在上述每一种情况下，当我们试图学习新的方面或主题时，并不会从头开始学习所有内容。我们从过去学到的知识中转移和利用我们的知识!

传统的机器学习和深度学习算法传统上被设计为独立工作。这些算法被训练来解决特定的任务。一旦特征空间分布发生变化，必须从头重建模型。迁移学习是一种克服孤立学习范式，利用为一项任务所获得的知识来解决相关任务的思想。

迁移学习的三个重要问题要使用迁移学习，必须回答以下三个重要问题:

(i)迁移什么?

这是整个过程的第一步，也是最重要的一步。为了提高目标任务的绩效，我们试图寻找哪些知识可以从源转移到目标的答案。我们应该努力确定知识的哪一部分是特定于源的，以及源和目标之间的共同点是什么。

(ii)何时迁移?

在某些情况下，为了知识而转移知识可能会使事情比改进任何东西都更糟糕(也称为负转移)。我们应该致力于利用迁移学习来提高目标任务的性能/结果，而不是降低它们。我们需要注意什么时候转移，什么时候不转移。

(iii)如何迁移?

一旦回答了“什么”和“什么时候”，我们就可以着手确定跨领域/任务实际转移知识的方法。这涉及到对现有算法和不同技术的改变。

### 9.5.2 三大迁移学习场景

(i) CNN作为固定特征提取器

以在ImageNet上预训练的CNN为例，删除最后一个完全连接层(该层的输出是用于ImageNet等不同任务的1000个类分数)，然后将CNN的其余部分作为新数据集的固定特征提取器处理。例如，在AlexNet中，这将为每一张包含在分类器之前的隐藏层激活的图像计算一个4096-D向量。我们称这些功能为CNN代码。提取出所有图像的4096-D代码后，为新数据集训练一个线性分类器(例如线性SVM或Softmax分类器)。

(ii) 微调CNN

第二种策略不仅是在新数据集的CNN之上替换和重新训练分类器，而且还通过继续反向传播来微调预先训练的网络的权重。译文：可以对CNN的所有层进行微调，也可以保持一些较早的层固定(由于过拟合的问题)，只微调网络的一些较高级别部分。这是由于观察到CNN的早期特征包含更多的通用特征(例如边缘检测器或色斑检测器)，这些特征应该对许多任务有用，但CNN的后几层逐渐变得更特定于原始数据集中包含的类的细节。例如，在ImageNet中，它包含许多狗的品种，CNN的代表性力量的很大一部分可能专门用于区分狗的品种。

(iii) 预训练

训练前的模型由于现代的CNN需要2-3周的时间在ImageNet上跨多个gpu进行训练，所以经常会看到人们发布最终的CNN检查点，以便其他可以使用该网络进行优化的人员使用。

### 9.5.3 何时以及如何进行微调?

如何决定应该对新数据集执行哪种类型的迁移学习?这是几个因素的函数，但最重要的两个因素是(i)新数据集的大小(小或大)(ii)其与原始数据集的相似性(例如，在图像的内容和类别方面类似imagenet，或非常不同，如显微镜图像)。请记住，CNN特性在早期的层中更通用，在后期的层中更特定于原始数据集，以下是4个主要场景的一些常见经验规则:

**(i)新数据集较小，与原始数据集相似。**

由于数据很小，由于过拟合的问题，对CNN进行微调并不是一个好主意。由于数据与原始数据相似，我们期望CNN中的高级特征也与这个数据集相关。因此，最好的方法可能是用CNN代码训练一个线性分类器。

**(ii)新数据集较大，与原始数据集相似**

因为我们有更多的数据，如果我们尝试微调整个网络，我们可以更有信心不会过度拟合训练数据。

**(iii)新数据集虽小，但与原始数据集差异很大**

由于数据很小，最好是只训练一个线性分类器。由于数据集非常不同，从网络的顶部训练分类器可能不是最好的，因为网络的顶部包含更多特定于数据集的特性。相反，从网络中较早的某处激活来训练支持向量机分类器可能会更好。

**(iv)新数据集很大，与原始数据集差异很大**

由于数据集非常大，我们可以从零开始训练一个CNN。然而，在实践中，使用预训练模型的权重进行初始化通常是有益的。在这种情况下，我们将有足够的数据和信心来微调整个网络。



# 10. RNN循环神经网络

## 引言

##### **为什么需要RNN（循环神经网络）**

普通的神经网络他们都只能单独的取处理一个个的输入，前一个输入和后一个输入是完全没有关系的。但是，某些任务需要能够更好的处理**序列**的信息，即前面的输入和后面的输入是有关系的。

> **比如，当我们在理解一句话意思时，孤立的理解这句话的每个词是不够的，我们需要处理这些词连接起来的整个序列；\*** ***当我们处理视频的时候，我们也不能只单独的去分析每一帧，而要分析这些帧连接起来的整个序列。**

**以nlp的一个最简单词性标注任务来说，将我 吃 苹果 三个单词标注词性为 我/nn 吃/v 苹果/nn。**

那么这个任务的输入就是：

我 吃 苹果 （已经分词好的句子）

这个任务的输出是：

*我/nn 吃/v 苹果/nn(词性标注好的句子)*

对于这个任务来说，我们当然可以直接用普通的神经网络来做，给网络的训练数据格式了就是我-> 我/nn 这样的多个单独的单词->词性标注好的单词。

***但是很明显，一个句子中，前一个单词其实对于当前单词的词性预测是有很大影响的，比如预测苹果的时候，由于前面的吃是一个动词，那么很显然苹果作为名词的概率就会远大于动词的概率，因为动词后面接名词很常见，而动词后面接动词很少见。\***

## 10.1 介绍

循环神经网络（Recurrent Neural Network, RNN）是一类以序列（sequence）数据为输入，在序列的演进方向进行递归（recursion）且所有节点（循环单元）按链式连接的递归神经网络（recursive neural network） 。

[![z8rEUf.jpg](https://s1.ax1x.com/2022/11/23/z8rEUf.jpg)](https://imgse.com/i/z8rEUf)

## 10.2 long short-term memory网络（LSTM）

LSTM单元是一个专门设计的逻辑单元，它将使循环神经网络在长期记忆任务中更有用，例如文本序列预测。

[![z8rn2Q.jpg](https://s1.ax1x.com/2022/11/23/z8rn2Q.jpg)](https://imgse.com/i/z8rn2Q)

## 10.3 LSTM应用

LSTM已经成功地应用于序列数据，特别是自然语言处理任务(即文本)。一些例子是:

(i)语言建模语言建模是许多自然语言处理任务的核心问题。经过训练的语言模型根据文本中先前使用的单词序列来学习单词出现的可能性。

(ii)机器翻译也称为序列对序列学习机器翻译是由计算机翻译文本，不需要人工参与。它也被称为自动翻译或即时翻译。

(iii)图像字幕

图像标题是生成图像文本描述的过程。
